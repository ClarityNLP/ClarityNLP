{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooking with ClarityNLP - Session #1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this session is to introduce you to writing basic queries using NLPQL.  For details on installing ClarityNLP, loading data, and tagging document types, please see our [documentation](https://claritynlp.readthedocs.io/en/latest/index.html).  We welcome questions via Slack or on [GitHub](https://github.com/ClarityNLP/ClarityNLP/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Run NLPQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run NLPQL, you must submit it to a ClarityNLP server either via API or via the ClarityNLP user interface.  If you are running a local instance, the API endpoint is typically `localhost:5000/nlpql`.  NLPQL should be POSTed as text/plain.  An example from [Postman](www.postman.com) is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Postman.png](assets/Postman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unfamiliar with using tools such as Postman, you can submit NLPQL via the ClarityNLP user interface running in a web browser. For local instances, this will be at [localhost:8200/runner](localhost:8200/runner). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLPQL_Runner.png](assets/NLPQL_Runner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run NLPQL directly from this notebook, then please use the following code.  You will need to edit the `url` variable to \"localhost:5000/\" or your ClarityNLP server IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClarityNLP notebook helpers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# This code below is only required for running ClarityNLP in Jupyter notebooks. It is not required if running NLPQL via API or the ClarityNLP GUI.\n",
    "\n",
    "import pandas as pd\n",
    "import claritynlp_notebook_helpers as claritynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Throughout these tutorials, we will prepend all examples with `limit 100;`.  This limits the server to analyzing a maxium of 100 documents, reducing runtime and compute load when testing new queries. Once a query is producing the expected output, removing this line will allow the full dataset to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1: Congestive Heart Failure\n",
    "For this first use case, our goal is to find patients with reduced ejection fraction and/or late stage CHF who are experiencing symptomatic orthopnea.  We will begin by breaking this into smaller components then combining into a comprehensive phenotype definition that can be shared across sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find mentions of \"Orthopnea\" in the patient chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a basic example, simply looking for the presence of a given term in the record.\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this NLPQL, copy/paste the above and submit via API or the ClarityNLP interface.  Or if you would like to run the NLPQL directoly within this notebook, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/10397/phenotype_intermediate\",\n",
      "    \"job_id\": \"10397\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=10397\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/10397/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/10328\",\n",
      "    \"phenotype_id\": \"10328\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/10540\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        10540\n",
      "    ],\n",
      "    \"results_viewer\": \"http://localhost:8200/?job=10397\",\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/10397\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 10;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small jobs with limits such as that above typically take less than 60 seconds to run.  Bigger jobs can take much (much) longer.  You can view your job's progress and see how ClarityNLP has broken up the query using the [Luigi Status Monitor](http://18.220.133.76:8082/static/visualiser/index.html).  Here is a screenshot of the above query running in Luigi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-08-28%20at%2010.27.36%20PM.png](assets/Luigi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Results\n",
    "There are two types of results from an NLPQL query: intermediate results and final results.  *Intermediate results* refer to all data that are extracted by the query.  *Final results* refer to only those patients or documents meeting a specified logic (eg. cohort criteria).  \n",
    "\n",
    "For the current task, we have not defined a cohort logic.  We asked only to find mentions of orthopnea, which is a data extraction task and will produce only intermediate results.  To download the intermediate results, you can navigate to the `intermediate_results_csv` URL returned by your API call or if you used this notebook, you can see tne URL and a preview below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://18.220.133.76:5000/job_results/300/phenotype_intermediate\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>end</th>\n",
       "      <th>experiencer</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>negation</th>\n",
       "      <th>nlpql_feature</th>\n",
       "      <th>owner</th>\n",
       "      <th>...</th>\n",
       "      <th>report_id</th>\n",
       "      <th>report_type</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b8609d5d982be0ca4e3d549</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-08-29 02:49:57.706000</td>\n",
       "      <td>300</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>clarity</td>\n",
       "      <td>...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Clip # [**Clip Number (Radiology) 35135**] Rea...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>86</td>\n",
       "      <td>54604</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b8609d5d982be0ca4e3d54a</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>32</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-08-29 02:49:57.710000</td>\n",
       "      <td>300</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>clarity</td>\n",
       "      <td>...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>72 year old woman with orthopnea REASON FOR THIS</td>\n",
       "      <td>1079230</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>23</td>\n",
       "      <td>54604</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b8609d5d982be0ca4e3d54b</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>44</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-08-29 02:49:57.711000</td>\n",
       "      <td>300</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>clarity</td>\n",
       "      <td>...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>PHYSICAL_EXAMINATION</td>\n",
       "      <td>pls eval for chf or other cause of orthopnea F...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>35</td>\n",
       "      <td>54604</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b8609d5d982be0ca4e3d54c</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-08-29 02:49:57.711000</td>\n",
       "      <td>300</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>clarity</td>\n",
       "      <td>...</td>\n",
       "      <td>1079230</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>HISTORY_PRESENT_ILLNESS</td>\n",
       "      <td>Orthopnea.</td>\n",
       "      <td>1079230</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>54604</td>\n",
       "      <td>Recent</td>\n",
       "      <td>Orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b8609d5d982be0ca4e3d54d</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>70</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-08-29 02:49:57.910000</td>\n",
       "      <td>300</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>clarity</td>\n",
       "      <td>...</td>\n",
       "      <td>769966</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Clip # [**Clip Number (Radiology) 13510**] Rea...</td>\n",
       "      <td>769966</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>61</td>\n",
       "      <td>17456</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  end experiencer  \\\n",
       "0  5b8609d5d982be0ca4e3d549      0            -1   95     Patient   \n",
       "1  5b8609d5d982be0ca4e3d54a      0            -1   32     Patient   \n",
       "2  5b8609d5d982be0ca4e3d54b      0            -1   44     Patient   \n",
       "3  5b8609d5d982be0ca4e3d54c      0            -1    9     Patient   \n",
       "4  5b8609d5d982be0ca4e3d54d      0            -1   70     Patient   \n",
       "\n",
       "                inserted_date  job_id  negation nlpql_feature    owner  \\\n",
       "0  2018-08-29 02:49:57.706000     300  Affirmed  hasOrthopnea  clarity   \n",
       "1  2018-08-29 02:49:57.710000     300  Affirmed  hasOrthopnea  clarity   \n",
       "2  2018-08-29 02:49:57.711000     300  Affirmed  hasOrthopnea  clarity   \n",
       "3  2018-08-29 02:49:57.711000     300  Affirmed  hasOrthopnea  clarity   \n",
       "4  2018-08-29 02:49:57.910000     300  Affirmed  hasOrthopnea  clarity   \n",
       "\n",
       "     ...      report_id  report_type                  section  \\\n",
       "0    ...        1079230    Radiology                  UNKNOWN   \n",
       "1    ...        1079230    Radiology                CONDITION   \n",
       "2    ...        1079230    Radiology     PHYSICAL_EXAMINATION   \n",
       "3    ...        1079230    Radiology  HISTORY_PRESENT_ILLNESS   \n",
       "4    ...         769966    Radiology                  UNKNOWN   \n",
       "\n",
       "                                            sentence  solr_id source start  \\\n",
       "0  Clip # [**Clip Number (Radiology) 35135**] Rea...  1079230  MIMIC    86   \n",
       "1   72 year old woman with orthopnea REASON FOR THIS  1079230  MIMIC    23   \n",
       "2  pls eval for chf or other cause of orthopnea F...  1079230  MIMIC    35   \n",
       "3                                         Orthopnea.  1079230  MIMIC     0   \n",
       "4  Clip # [**Clip Number (Radiology) 13510**] Rea...   769966  MIMIC    61   \n",
       "\n",
       "  subject  temporality       term  \n",
       "0   54604       Recent  orthopnea  \n",
       "1   54604       Recent  orthopnea  \n",
       "2   54604       Recent  orthopnea  \n",
       "3   54604       Recent  Orthopnea  \n",
       "4   17456       Recent  orthopnea  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, you may notice that the `TermFinder` function peforms a picks up both negated and affirmed cases as well as historical, hypothetical, and any other mentions.  TermFinder can be tuned to pull only specific results. Such as in the example below, which only gets positive mentions.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many term searchers are actually looking for non-negated, non-hypothetical, subject=patient mentions, we provide a convenient function `ProviderAssertion` to capture those mentions without needing to configure TermFinder. \n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Find NYHA Class III/IV patients or those with EF<30%\n",
    "For the next component of this tutorial, we will aim to extract specific values about CHF from the chart.  This is commonly done with the [ValueExtraction](https://claritynlp.readthedocs.io/en/latest/developer_guide/algorithms/value_extraction.html) function.  Value extractions can be numeric as well as an enumerated list of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will be searching for ejection fraction values using a very simple algorithm.  Specifically, we will be looking for certain terms and subsequent values that would be typical for EF values.  (There are many more sophisticated methods to find ejection fraction (e.g [Kim et al](https://www.ncbi.nlm.nih.gov/pubmed/28163196)).)  We will then constrain the \"final\" cohort to only those with an EF < 30.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://18.220.133.76:5000/job_results/314/phenotype_intermediate\",\n",
      "    \"job_id\": \"314\",\n",
      "    \"luigi_task_monitoring\": \"http://18.220.133.76:8082/static/visualiser/index.html#search__search=job=314\",\n",
      "    \"main_results_csv\": \"http://18.220.133.76:5000/job_results/314/phenotype\",\n",
      "    \"phenotype_config\": \"http://18.220.133.76:5000/phenotype_id/314\",\n",
      "    \"phenotype_id\": \"314\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://18.220.133.76:5000/pipeline_id/486\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        486\n",
      "    ],\n",
      "    \"results_viewer\": \"?job=314\",\n",
      "    \"status_endpoint\": \"http://18.220.133.76:5000/status/314\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `final` declaration refers to a cohort definition and typically involves some logic.  So in this case we defined an extraction process to pull all values between 10 and 85 following EF, LVEF, etc.  We then specified a `context`, meaning that the logic should operate on the level of a patient.  (The other option is Document context, which we will describe in a future session.)  Our logical rule stated that patients with an EjectionFraction <= 30 would make our criteria for a Low EF Patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be found at the main_results_csv URL from your API response, or if  you ran here in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://18.220.133.76:5000/job_results/314/phenotype\n"
     ]
    }
   ],
   "source": [
    "print(main_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>condition</th>\n",
       "      <th>context_type</th>\n",
       "      <th>dimension_X</th>\n",
       "      <th>dimension_Y</th>\n",
       "      <th>dimension_Z</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "      <th>units</th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b861463d982be111ec73acc</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-08-29 03:34:48.927000</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>28785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejection fraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b861463d982be111ec73acd</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>2018-08-29 03:34:49.370000</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>66</td>\n",
       "      <td>57911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LVEF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b861463d982be111ec73ace</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>APPROX</td>\n",
       "      <td>subject</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-08-29 03:34:49.566000</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>21</td>\n",
       "      <td>68579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ejection fraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b861463d982be111ec73acf</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>2018-08-29 03:34:49.628000</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>116</td>\n",
       "      <td>1944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LVEF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b861463d982be111ec73ad0</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>2018-08-29 03:34:49.629000</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>104</td>\n",
       "      <td>1944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ejection fraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code condition context_type  \\\n",
       "0  5b861463d982be111ec73acc     25            -1     EQUAL      subject   \n",
       "1  5b861463d982be111ec73acd     25            -1     EQUAL      subject   \n",
       "2  5b861463d982be111ec73ace     25            -1    APPROX      subject   \n",
       "3  5b861463d982be111ec73acf     25            -1     EQUAL      subject   \n",
       "4  5b861463d982be111ec73ad0     25            -1     EQUAL      subject   \n",
       "\n",
       "   dimension_X  dimension_Y  dimension_Z  end               inserted_date  \\\n",
       "0         15.0         -1.0          NaN   23  2018-08-29 03:34:48.927000   \n",
       "1         20.0         -1.0          NaN   74  2018-08-29 03:34:49.370000   \n",
       "2         30.0         -1.0          NaN   58  2018-08-29 03:34:49.566000   \n",
       "3         20.0         -1.0          NaN  126  2018-08-29 03:34:49.628000   \n",
       "4         20.0         -1.0          NaN  127  2018-08-29 03:34:49.629000   \n",
       "\n",
       "   ...   source  start  subject temporality term               text  units  \\\n",
       "0  ...    MIMIC      0    28785         NaN  NaN  Ejection fraction    NaN   \n",
       "1  ...    MIMIC     66    57911         NaN  NaN               LVEF    NaN   \n",
       "2  ...    MIMIC     21    68579         NaN  NaN  ejection fraction    NaN   \n",
       "3  ...    MIMIC    116     1944         NaN  NaN               LVEF    NaN   \n",
       "4  ...    MIMIC    104     1944         NaN  NaN  ejection fraction    NaN   \n",
       "\n",
       "   value  value1 value2  \n",
       "0   15.0     NaN    NaN  \n",
       "1   20.0     NaN    NaN  \n",
       "2   30.0     NaN    NaN  \n",
       "3   20.0     NaN    NaN  \n",
       "4   20.0     NaN    NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use ValueExtraction to pull out an enumerated value set (rather than a quantitative value).  See the example below for NYHA class.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://18.220.133.76:5000/job_results/315/phenotype_intermediate\",\n",
      "    \"job_id\": \"315\",\n",
      "    \"luigi_task_monitoring\": \"http://18.220.133.76:8082/static/visualiser/index.html#search__search=job=315\",\n",
      "    \"main_results_csv\": \"http://18.220.133.76:5000/job_results/315/phenotype\",\n",
      "    \"phenotype_config\": \"http://18.220.133.76:5000/phenotype_id/315\",\n",
      "    \"phenotype_id\": \"315\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://18.220.133.76:5000/pipeline_id/487\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        487\n",
      "    ],\n",
      "    \"results_viewer\": \"?job=315\",\n",
      "    \"status_endpoint\": \"http://18.220.133.76:5000/status/315\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>condition</th>\n",
       "      <th>dimension_X</th>\n",
       "      <th>dimension_Y</th>\n",
       "      <th>dimension_Z</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "      <th>units</th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b86179b2d766700725ffa55</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>iii</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>2018-08-29 03:48:43.050000</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>249</td>\n",
       "      <td>9547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b86179b2d766700725ffa56</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>iii</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>2018-08-29 03:48:43.055000</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>18</td>\n",
       "      <td>9547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b86179c2d766700725ffa57</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>iii</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-08-29 03:48:44.081000</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>5</td>\n",
       "      <td>32158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b86179c2d766700725ffa58</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>iii</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-08-29 03:48:44.448000</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>24</td>\n",
       "      <td>90546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b86179c2d766700725ffa59</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>iii</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-08-29 03:48:44.449000</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>24</td>\n",
       "      <td>90546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code condition dimension_X  \\\n",
       "0  5b86179b2d766700725ffa55     75            -1     EQUAL         iii   \n",
       "1  5b86179b2d766700725ffa56     75            -1     EQUAL         iii   \n",
       "2  5b86179c2d766700725ffa57     75            -1     EQUAL         iii   \n",
       "3  5b86179c2d766700725ffa58     75            -1     EQUAL         iii   \n",
       "4  5b86179c2d766700725ffa59     75            -1     EQUAL         iii   \n",
       "\n",
       "   dimension_Y  dimension_Z  end               inserted_date  job_id  ...    \\\n",
       "0           -1          NaN  266  2018-08-29 03:48:43.050000     315  ...     \n",
       "1           -1          NaN   35  2018-08-29 03:48:43.055000     315  ...     \n",
       "2           -1          NaN   26  2018-08-29 03:48:44.081000     315  ...     \n",
       "3           -1          NaN   52  2018-08-29 03:48:44.448000     315  ...     \n",
       "4           -1          NaN   52  2018-08-29 03:48:44.449000     315  ...     \n",
       "\n",
       "   source start subject  temporality  term  text units  value value1 value2  \n",
       "0   MIMIC   249    9547          NaN   NaN  NYHA   NaN    iii    NaN    NaN  \n",
       "1   MIMIC    18    9547          NaN   NaN  NYHA   NaN    iii    NaN    NaN  \n",
       "2   MIMIC     5   32158          NaN   NaN  NYHA   NaN    iii    NaN    NaN  \n",
       "3   MIMIC    24   90546          NaN   NaN  NYHA   NaN    iii    NaN    NaN  \n",
       "4   MIMIC    24   90546          NaN   NaN  NYHA   NaN    iii    NaN    NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bringing the criteria together to find the target CHF cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final step in example 1, we want to bring together the above criteria to generate our final cohort.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://18.220.133.76:5000/job_results/321/phenotype_intermediate\",\n",
      "    \"job_id\": \"321\",\n",
      "    \"luigi_task_monitoring\": \"http://18.220.133.76:8082/static/visualiser/index.html#search__search=job=321\",\n",
      "    \"main_results_csv\": \"http://18.220.133.76:5000/job_results/321/phenotype\",\n",
      "    \"phenotype_config\": \"http://18.220.133.76:5000/phenotype_id/321\",\n",
      "    \"phenotype_id\": \"321\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://18.220.133.76:5000/pipeline_id/499\",\n",
      "        \"http://18.220.133.76:5000/pipeline_id/500\",\n",
      "        \"http://18.220.133.76:5000/pipeline_id/501\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        499,\n",
      "        500,\n",
      "        501\n",
      "    ],\n",
      "    \"results_viewer\": \"?job=321\",\n",
      "    \"status_endpoint\": \"http://18.220.133.76:5000/status/321\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Final CHF Cohort\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_id_x</th>\n",
       "      <th>_id_y</th>\n",
       "      <th>context_type</th>\n",
       "      <th>job_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>nlpql_feature</th>\n",
       "      <th>nlpql_feature_x</th>\n",
       "      <th>nlpql_feature_y</th>\n",
       "      <th>owner</th>\n",
       "      <th>phenotype_final</th>\n",
       "      <th>phenotype_id</th>\n",
       "      <th>raw_definition_text</th>\n",
       "      <th>report_date_x</th>\n",
       "      <th>report_date_y</th>\n",
       "      <th>report_id_x</th>\n",
       "      <th>report_id_y</th>\n",
       "      <th>sentence_x</th>\n",
       "      <th>sentence_y</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b86a0de2d766709fcba2a83</td>\n",
       "      <td>5b86a0de2d766709fcba2a73</td>\n",
       "      <td>5b86a0da2d766709e3ba29a5</td>\n",
       "      <td>subject</td>\n",
       "      <td>2018-08-29 13:34:22.295000</td>\n",
       "      <td>321</td>\n",
       "      <td>SevereCHFwithOrthopnea</td>\n",
       "      <td>SevereCHF</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>321</td>\n",
       "      <td>True</td>\n",
       "      <td>321</td>\n",
       "      <td>SevereCHF AND hasOrthopnea</td>\n",
       "      <td>2195-08-21T00:00:00Z</td>\n",
       "      <td>2195-10-16T00:00:00Z</td>\n",
       "      <td>86213</td>\n",
       "      <td>1156997</td>\n",
       "      <td>The left ventricular ejection fraction is appr...</td>\n",
       "      <td>64 year old man with DOE, orthopnea, h/o CHF R...</td>\n",
       "      <td>68579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b86a0de2d766709fcba2a84</td>\n",
       "      <td>5b86a0de2d766709fcba2a73</td>\n",
       "      <td>5b86a0da2d766709e3ba29a6</td>\n",
       "      <td>subject</td>\n",
       "      <td>2018-08-29 13:34:22.295000</td>\n",
       "      <td>321</td>\n",
       "      <td>SevereCHFwithOrthopnea</td>\n",
       "      <td>SevereCHF</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>321</td>\n",
       "      <td>True</td>\n",
       "      <td>321</td>\n",
       "      <td>SevereCHF AND hasOrthopnea</td>\n",
       "      <td>2195-08-21T00:00:00Z</td>\n",
       "      <td>2195-10-16T00:00:00Z</td>\n",
       "      <td>86213</td>\n",
       "      <td>1156997</td>\n",
       "      <td>The left ventricular ejection fraction is appr...</td>\n",
       "      <td>Dyspnea on exertion, orthopnea, history of CHF...</td>\n",
       "      <td>68579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                     _id_x  \\\n",
       "0  5b86a0de2d766709fcba2a83  5b86a0de2d766709fcba2a73   \n",
       "1  5b86a0de2d766709fcba2a84  5b86a0de2d766709fcba2a73   \n",
       "\n",
       "                      _id_y context_type                    job_date  job_id  \\\n",
       "0  5b86a0da2d766709e3ba29a5      subject  2018-08-29 13:34:22.295000     321   \n",
       "1  5b86a0da2d766709e3ba29a6      subject  2018-08-29 13:34:22.295000     321   \n",
       "\n",
       "            nlpql_feature nlpql_feature_x nlpql_feature_y  owner  \\\n",
       "0  SevereCHFwithOrthopnea       SevereCHF    hasOrthopnea    321   \n",
       "1  SevereCHFwithOrthopnea       SevereCHF    hasOrthopnea    321   \n",
       "\n",
       "   phenotype_final  phenotype_id         raw_definition_text  \\\n",
       "0             True           321  SevereCHF AND hasOrthopnea   \n",
       "1             True           321  SevereCHF AND hasOrthopnea   \n",
       "\n",
       "          report_date_x         report_date_y  report_id_x  report_id_y  \\\n",
       "0  2195-08-21T00:00:00Z  2195-10-16T00:00:00Z        86213      1156997   \n",
       "1  2195-08-21T00:00:00Z  2195-10-16T00:00:00Z        86213      1156997   \n",
       "\n",
       "                                          sentence_x  \\\n",
       "0  The left ventricular ejection fraction is appr...   \n",
       "1  The left ventricular ejection fraction is appr...   \n",
       "\n",
       "                                          sentence_y  subject  \n",
       "0  64 year old man with DOE, orthopnea, h/o CHF R...    68579  \n",
       "1  Dyspnea on exertion, orthopnea, history of CHF...    68579  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case, we may need to increase our limit beyond 100 documents to find many matching patients, because multiple criteria are required and a small sample may not be enough.  Try increasing to 500 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Results through the ClarityNLP UI\n",
    "Downloading the raw CSV results is handy for analysis and data manipulation.  However, a domain-oriented end user may be more interested in just exploring and validating the final results without getting into all the programmatic details.  That's where the Results Viewer comes in, which in a typical installation will be found at localhost:8200/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-08-29%20at%209.33.35%20AM.png](assets/Clarity Validator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #2: Capturing Information on Patient Race\n",
    "Although there are many useful [core algorithms](https://claritynlp.readthedocs.io/en/latest/developer_guide/index.html#task-algorithms) in ClarityNLP, users will frequently want to extend its functionality.  In this second example, we will explore how to extend ClarityNLP when the built in algorithms are inadequate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'd like to identify the patient's race.  While some version of this could probably we done with simple search terms, a custom algorithm will likely be necessary.  Below is an example of a custom Python algorithm written to extract race information from a document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into the details, this algorithm parses text to find race information, normalizes it to standard terms, and passes back the result.  In order to run this algorithm using NLPQL in ClarityNLP, we create what is called a custom task.  Below is code that creates the CustomTask wrapping this function and provides it with the documents and handling of result ouput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "                    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files can be split into two or can be combined as shown in the final custom task below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "from collections import namedtuple\n",
    "from tasks.task_utilities import BaseTask\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "class RaceFinderTask(BaseTask):\n",
    "    \"\"\"\n",
    "    A custom task for finding a patient's race.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This race task can be called in NLPQL as follows:\n",
    "\n",
    "```java\n",
    "    limit 100;\n",
    "\n",
    "    phenotype \"Race Finder\" version \"1\";\n",
    "    include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "    documentset DischargeSummaries:\n",
    "        Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "    define RaceFinderFunction:\n",
    "        Clarity.RaceFinderTask({\n",
    "            documentset: [DischargeSummaries]\n",
    "        });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  This example is our first time using `documentset`, which allows us to specify a targeted list of documents such as Discharge Summaries or Radiology notes etc.  We will cover this is greater detail in future Cooking sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://18.220.133.76:5000/job_results/322/phenotype_intermediate\",\n",
      "    \"job_id\": \"322\",\n",
      "    \"luigi_task_monitoring\": \"http://18.220.133.76:8082/static/visualiser/index.html#search__search=job=322\",\n",
      "    \"main_results_csv\": \"http://18.220.133.76:5000/job_results/322/phenotype\",\n",
      "    \"phenotype_config\": \"http://18.220.133.76:5000/phenotype_id/322\",\n",
      "    \"phenotype_id\": \"322\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://18.220.133.76:5000/pipeline_id/502\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        502\n",
      "    ],\n",
      "    \"results_viewer\": \"?job=322\",\n",
      "    \"status_endpoint\": \"http://18.220.133.76:5000/status/322\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "phenotype \"Race Finder\" version \"1\";\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "define RaceFinderFunction:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>nlpql_feature</th>\n",
       "      <th>owner</th>\n",
       "      <th>phenotype_final</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>...</th>\n",
       "      <th>report_date</th>\n",
       "      <th>report_id</th>\n",
       "      <th>report_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>value</th>\n",
       "      <th>value_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b86a5fc2d76670a1377c786</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-08-29 13:56:12.628000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2106-07-16T00:00:00Z</td>\n",
       "      <td>10851</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Overweight white female.</td>\n",
       "      <td>10851</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>11</td>\n",
       "      <td>11350</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b86a6002d76670a1977c786</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>2018-08-29 13:56:16.440000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2106-05-03T00:00:00Z</td>\n",
       "      <td>8534</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Patient is a 46-year-old white female with his...</td>\n",
       "      <td>8534</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>25</td>\n",
       "      <td>15160</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b86a60a2d76670a1677c786</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>2018-08-29 13:56:26.021000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2152-03-14T00:00:00Z</td>\n",
       "      <td>10838</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>In general, the patient was a middle-aged whit...</td>\n",
       "      <td>10838</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>42</td>\n",
       "      <td>26693</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b86a60c2d76670a1377c787</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-29 13:56:28.023000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2187-05-10T00:00:00Z</td>\n",
       "      <td>10862</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Elderly caucasian gentleman with Parkinsonian ...</td>\n",
       "      <td>10862</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b86a60d2d76670a1377c788</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>362</td>\n",
       "      <td>2018-08-29 13:56:29.182000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2100-10-19T00:00:00Z</td>\n",
       "      <td>10863</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Past Medical History: Hyperchol HTN Afib with ...</td>\n",
       "      <td>10863</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>347</td>\n",
       "      <td>25436</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  end  \\\n",
       "0  5b86a5fc2d76670a1377c786     75            -1   23   \n",
       "1  5b86a6002d76670a1977c786     25            -1   37   \n",
       "2  5b86a60a2d76670a1677c786     50            -1   54   \n",
       "3  5b86a60c2d76670a1377c787     75            -1   27   \n",
       "4  5b86a60d2d76670a1377c788     75            -1  362   \n",
       "\n",
       "                inserted_date  job_id       nlpql_feature    owner  \\\n",
       "0  2018-08-29 13:56:12.628000     322  RaceFinderFunction  clarity   \n",
       "1  2018-08-29 13:56:16.440000     322  RaceFinderFunction  clarity   \n",
       "2  2018-08-29 13:56:26.021000     322  RaceFinderFunction  clarity   \n",
       "3  2018-08-29 13:56:28.023000     322  RaceFinderFunction  clarity   \n",
       "4  2018-08-29 13:56:29.182000     322  RaceFinderFunction  clarity   \n",
       "\n",
       "   phenotype_final  pipeline_id       ...                  report_date  \\\n",
       "0            False          502       ...         2106-07-16T00:00:00Z   \n",
       "1            False          502       ...         2106-05-03T00:00:00Z   \n",
       "2            False          502       ...         2152-03-14T00:00:00Z   \n",
       "3            False          502       ...         2187-05-10T00:00:00Z   \n",
       "4            False          502       ...         2100-10-19T00:00:00Z   \n",
       "\n",
       "  report_id        report_type  \\\n",
       "0     10851  Discharge summary   \n",
       "1      8534  Discharge summary   \n",
       "2     10838  Discharge summary   \n",
       "3     10862  Discharge summary   \n",
       "4     10863  Discharge summary   \n",
       "\n",
       "                                            sentence solr_id  source start  \\\n",
       "0                           Overweight white female.   10851   MIMIC    11   \n",
       "1  Patient is a 46-year-old white female with his...    8534   MIMIC    25   \n",
       "2  In general, the patient was a middle-aged whit...   10838   MIMIC    42   \n",
       "3  Elderly caucasian gentleman with Parkinsonian ...   10862   MIMIC     8   \n",
       "4  Past Medical History: Hyperchol HTN Afib with ...   10863   MIMIC   347   \n",
       "\n",
       "   subject      value value_normalized  \n",
       "0    11350      white            white  \n",
       "1    15160      white            white  \n",
       "2    26693      white            white  \n",
       "3     1819  caucasian            white  \n",
       "4    25436  caucasian            white  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Combining race with other criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably gathered, you can now write NLPQL that will look for all patients matching our CHF criteria with the race information extracted above.  The NLPQL would look like this:\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "\n",
    "//documentsets\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "\n",
    "define Race:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "       \n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "\n",
    "define BlackRace:\n",
    "    where Race.normalized_value = 'black';\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "\n",
    "define final BlackSevereCHFPatient:\n",
    "    where SevereCHF AND BlackRace;\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
